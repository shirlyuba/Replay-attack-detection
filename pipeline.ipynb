{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2xR2INFxcxZy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from skimage.io import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4lQOlb3Oc3jp"
   },
   "outputs": [],
   "source": [
    "for cls in ['Real', 'Fake', 'Test']:\n",
    "    for path in os.listdir('Video/' + cls):\n",
    "        vs = cv2.VideoCapture(os.path.join('Video', cls, path))\n",
    "        read = 0\n",
    "        saved = 0\n",
    "        print(os.path.join('Video', cls, path))\n",
    "\n",
    "        while True:\n",
    "            (grabbed, frame) = vs.read()\n",
    "\n",
    "            if not grabbed:\n",
    "                break\n",
    "\n",
    "            read += 1\n",
    "\n",
    "            if read >= 20 and read <= 220:\n",
    "                rgb_frame = frame[:, :, ::-1]\n",
    "                if not os.path.exists('Dataset/' + cls + '/' + path[:-4]):\n",
    "                    os.mkdir('Dataset/' + cls + '/' + path[:-4])\n",
    "                imsave('Dataset/' + cls + '/' + path[:-4] + '/' + str(read) + '.png', rgb_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OH-jSoAuCUR"
   },
   "outputs": [],
   "source": [
    "eps = 20\n",
    "\n",
    "def A_feature(img1, img2):\n",
    "    return np.abs(img1 - img2)\n",
    "\n",
    "def A_feature_map(imgs):\n",
    "    diff = np.array([])\n",
    "    for i in range(len(imgs)-1):\n",
    "        diff = np.append(diff, A_feature(imgs[i], imgs[i+1]))\n",
    "    diff = diff.reshape(shape)\n",
    "    return diff\n",
    "\n",
    "def F_feature(img1, img2):\n",
    "    return (np.abs(img1 - img2) > eps).astype(int) * 255\n",
    "\n",
    "def F_feature_map(imgs):\n",
    "    diff = np.array([])\n",
    "    for i in range(len(imgs)-1):\n",
    "        diff = np.append(diff, F_feature(imgs[i], imgs[i+1]))\n",
    "    diff = diff.reshape(shape)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcz30l7KtrkF"
   },
   "outputs": [],
   "source": [
    "for cls in ['Real', 'Fake', 'Test']:\n",
    "    for path in os.listdir('Dataset/' + cls):\n",
    "        print(cls, path)\n",
    "        if os.path.exists(os.path.join('maps', cls + \"_\" +path+\".npy\")):\n",
    "            continue\n",
    "        diff = np.array([])\n",
    "        shape = 0\n",
    "        for file in range(20, 120):\n",
    "            if os.path.exists(os.path.join('Dataset/', cls, path, str(file) + '.png')):\n",
    "                if file != 20:\n",
    "                    prev_img = curr_img\n",
    "                curr_img = cv2.imread(os.path.join('Dataset/', cls, path, str(file) + '.png'))\n",
    "                if file != 20:\n",
    "                    diff = np.append(diff, F_feature(prev_img, curr_img))\n",
    "                shape = curr_img.shape\n",
    "        shape = tuple([-1] + list(shape))\n",
    "        diff = diff.reshape(shape)\n",
    "        new_data = np.array([])\n",
    "        for img in diff:\n",
    "            new_img = cv2.resize(img, (256, 256))\n",
    "            new_data = np.append(new_data, new_img)\n",
    "        new_data = new_data.reshape(-1, 256, 256, 3)\n",
    "        np.save(os.path.join('maps', cls + \"_\" +path+\".npy\"), new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0eFJdK6_ecLc"
   },
   "outputs": [],
   "source": [
    "true_data = np.array([])\n",
    "for path in os.listdir('maps'):\n",
    "    if path.split(\"_\")[0] == 'Real':\n",
    "        true_data = np.append(true_data, np.load('maps/' + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vsdnqASWY3h2"
   },
   "outputs": [],
   "source": [
    "true_data = true_data.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLtSTZa6XD9O"
   },
   "outputs": [],
   "source": [
    "false_data = np.array([])\n",
    "for path in os.listdir('maps'):\n",
    "    if path.split(\"_\")[0] == 'Fake':\n",
    "        false_data = np.append(false_data, np.load('maps/' + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6n_I6KiZFf6"
   },
   "outputs": [],
   "source": [
    "false_data = false_data.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gb3HIF68ZI2T"
   },
   "outputs": [],
   "source": [
    "true_test = np.array([])\n",
    "for path in os.listdir('maps'):\n",
    "    if path.split(\"_\")[0] == 'Test' and path.split(\"_\")[1] == 'true':\n",
    "        true_test = np.append(true_test, np.load('maps/' + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TZTS6xSdZrjO",
    "outputId": "7af43c85-d8cb-4a67-d68e-38bbeb8bb759"
   },
   "outputs": [],
   "source": [
    "false_test = np.array([])\n",
    "for path in os.listdir('maps'):\n",
    "    if path.split(\"_\")[0] == 'Test' and path.split(\"_\")[1] == 'false':\n",
    "        false_test = np.append(false_test, np.load('maps/' + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wq1Jlz-WZxVn"
   },
   "outputs": [],
   "source": [
    "false_test = false_test.reshape(-1, 256, 256, 3)\n",
    "true_test = true_test.reshape(-1, 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRVUHMHOZ20O",
    "outputId": "97e0aac2-59a6-4585-8e24-9aec05f683ed"
   },
   "outputs": [],
   "source": [
    "true_test.shape, false_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vCy5K8A_Z9HZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPDYO5M4aEVf"
   },
   "outputs": [],
   "source": [
    "X = np.append(true_data, false_data).reshape(-1, 256, 256, 3)\n",
    "Y = [1] * len(true_data) + [0] * len(false_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5Z1jEZTdO1P"
   },
   "outputs": [],
   "source": [
    "true_data = []\n",
    "false_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZ4VEvlQaJ_y"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uIk8B4YflJLN"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV0kAjW6aaRL"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, flist, transform, X, y):\n",
    "        self.root = root\n",
    "        self.imlist = flist\n",
    "        self.transform = transform\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = Image.fromarray(self.X[index], 'RGB'), self.y[index]\n",
    "        img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Psp7pCwPabNd"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform_for_train_and_val = transforms.Compose(\n",
    "    [   \n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "batch_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1XFFcbJdgMU"
   },
   "outputs": [],
   "source": [
    "trainset = CustomDataset('./data/train/train', 'dd', transform_for_train_and_val, X_train, y_train)\n",
    "valset = CustomDataset('./data/train/train', 'dd', transform_for_train_and_val, X_test, y_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=8, shuffle=True, pin_memory=True)                          \n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bdwklph9d27r"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "1f3362de27cc4cf086568d7ba6f47a84",
      "06f4daed54834229bd39ed00588c8cd3",
      "a96f4f57da9f4f7ea9abced04b6135fb",
      "fbf9886cdd8c48f3bb3e194939e1b63f",
      "5038d67d35b448409aea3e2a008b4c3c",
      "2e46656ca04a421a9cbcf506e67537e8",
      "4e2e96e9bbe14bba9acb549723d14624",
      "effa53e54ffb45bebb27e0bc1e61e483"
     ]
    },
    "id": "PORbD4Q23Mi_",
    "outputId": "3d771c5f-833b-4bd4-d7dc-13e68844e018"
   },
   "outputs": [],
   "source": [
    "custom_num_classes = 2\n",
    "\n",
    "model = models.squeezenet1_1(pretrained=True)\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Conv2d(512, custom_num_classes, kernel_size=1),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.AvgPool2d(13)\n",
    ")\n",
    "model.forward = lambda x: model.classifier(model.features(x)).view(x.size(0), custom_num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03kPRG8Qd7rU"
   },
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXlBewYPeI_0"
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2SEKp7nXlu5k"
   },
   "outputs": [],
   "source": [
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "optimizer = optim.SGD(params_to_update, lr=0.0001, momentum=0.91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QAkGCTNG8zbb"
   },
   "outputs": [],
   "source": [
    "init_model = torch.load('final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8OzJsEyX9Bja",
    "outputId": "ff8f4190-4b28-4bc4-d6ff-ea5cf750f58f"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(init_model['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UGom1ui7p80"
   },
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JQHcg5Orlw26"
   },
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnhzEWzKlzAh"
   },
   "outputs": [],
   "source": [
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3Vr61ufl0Su"
   },
   "outputs": [],
   "source": [
    "def run_epoch(epoch, is_train):\n",
    "  \"\"\"\n",
    "  Training and evaluaton loop over samples\n",
    "  Args:\n",
    "      train_mode (bool): True for train mode\n",
    "  \"\"\"\n",
    "    if is_train:\n",
    "        model.train()\n",
    "        loader = trainloader\n",
    "        print(\"Training epoch: \", epoch + 1, \"/\", num_epochs)\n",
    "    else:\n",
    "        model.eval()\n",
    "        loader = valloader\n",
    "        print('Validation')\n",
    "      \n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "\n",
    "    for i, data in tqdm.tqdm_notebook(enumerate(loader)):\n",
    "        images, labels = data\n",
    "\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total += images.data.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "      \n",
    "    print('Loss: {:.3f}, accuracy: {:.3f}'.format(running_loss / (i + 1), correct / total * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcdYHTnHl4bf"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hz9AB81tl7yK"
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "  #training\n",
    "    run_epoch(epoch, is_train=True)\n",
    "\n",
    "  #validation\n",
    "    with torch.no_grad():\n",
    "        run_epoch(epoch, is_train=False) \n",
    "\n",
    "    state = {\n",
    "          'epoch': epoch + 1,\n",
    "          'state_dict': model.state_dict(),\n",
    "          'optimizer' : optimizer.state_dict()\n",
    "          }\n",
    "\n",
    "    torch.save(state, str(epoch) + '_final_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5GXa8nCmADw"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U3-UUGXPyk8w"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "y_pred = []\n",
    "y_probas = []\n",
    "\n",
    "#val\n",
    "for x in X_test:\n",
    "    img = Image.fromarray(x, \"RGB\")\n",
    "    img = transform_for_train_and_val(img)\n",
    "    im = Variable(img, requires_grad=True).unsqueeze(0)\n",
    "    y_pred.append(int(model(im.cuda()).argmax().cpu().numpy()))\n",
    "    y_probas.append(F.softmax(model(im.cuda()))[0][1].cpu().detach().numpy())\n",
    "\n",
    "#test\n",
    "# y_test = [0]*len(false_test)+[1]*len(true_test)\n",
    "# for x in false_test:\n",
    "#     img = Image.fromarray(x, \"RGB\")\n",
    "#     img = transform_for_train_and_val(img)\n",
    "#     im = Variable(img, requires_grad=True).unsqueeze(0)\n",
    "#     y_pred.append(int(model(im.cuda()).argmax().cpu().numpy()))\n",
    "#     y_probas.append(F.softmax(model(im.cuda()))[0][1].cpu().detach().numpy())\n",
    "# for x in true_test:\n",
    "#     img = Image.fromarray(x, \"RGB\")\n",
    "#     img = transform_for_train_and_val(img)\n",
    "#     im = Variable(img, requires_grad=True).unsqueeze(0)\n",
    "#     y_pred.append(int(model(im.cuda()).argmax().cpu().numpy()))\n",
    "#     y_probas.append(F.softmax(model(im.cuda()))[0][0].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nCKm1O2wytAS",
    "outputId": "73fa1fd0-0bc5-4c77-8e82-1716bcc7f7cc"
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.precision_recall_fscore_support(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gK7-1qqYyvU3"
   },
   "outputs": [],
   "source": [
    "def get_far_frr(y_true, y_pred, threshold):\n",
    "    far = sum([1 for i in range(len(y_pred)) if y_pred[i] >= threshold and y_true[i]==0])/(len(y_true)-sum(y_true))\n",
    "    frr = sum([1 for i in range(len(y_pred)) if y_pred[i] <= threshold and y_true[i]==1])/sum(y_true)\n",
    "    return far, frr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IVHkAEvvytP"
   },
   "outputs": [],
   "source": [
    "def get_far_frr_lists(y_true, y_pred, thresholds=np.arange(0, 1.01, 0.01)):\n",
    "    far_list = []\n",
    "    frr_list = []\n",
    "    for t in thresholds:\n",
    "        far, frr = get_far_frr(y_true, y_pred, t)\n",
    "        far_list.append(far)\n",
    "        frr_list.append(frr)\n",
    "    return far_list, frr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Wd46qCx7AZq"
   },
   "outputs": [],
   "source": [
    "far, frr = get_far_frr_lists(y_test, y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cgj3pmd6x9UX"
   },
   "outputs": [],
   "source": [
    "def eer(far_list, frr_list, thresholds):\n",
    "    eer_1 = far_list[np.argmin(np.absolute((np.asarray(far_list) - np.asarray(frr_list))))]\n",
    "    eer_2 = frr_list[np.argmin(np.absolute((np.asarray(far_list) - np.asarray(frr_list))))]\n",
    "    return eer_1, eer_2, thresholds[np.nanargmin(np.absolute((np.asarray(far_list) - np.asarray(frr_list))))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pnzckzcu7Y_p",
    "outputId": "a5a6d47c-550e-4dd7-dafa-bf4accc65e73"
   },
   "outputs": [],
   "source": [
    "eer(far, frr, np.arange(0, 1.01, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFPsXfsv7tPf"
   },
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2sYvr0SwXkU"
   },
   "outputs": [],
   "source": [
    "def DETCurve(far, frr, ticks = np.arange(0.00, 0.31, 0.01)):\n",
    "    plt.rcParams[\"figure.figsize\"] = [15, 10]\n",
    "    plt.plot(far, frr, linestyle='-', color='blue', linewidth=2, marker=\".\", markersize=10)\n",
    "    plt.plot(ticks, ticks, color='red', linestyle='--', linewidth=1)\n",
    "    plt.xlim((0, 0.3))\n",
    "    plt.ylim((0, 0.3))\n",
    "    plt.xticks(ticks, labels=[str(i) +'%' for i in range(0, 31)], size=15)\n",
    "    plt.yticks(ticks, labels=[str(i) +'%' for i in range(0, 31)], size=15)\n",
    "    plt.ylabel(\"Доля ложных доступов (FAR)\", fontsize=20)\n",
    "    plt.xlabel(\"Доля ложных отказов (FRR)\", fontsize=20)\n",
    "    plt.title(\"Ошибки модели на разных порогах\", fontsize=25)\n",
    "    plt.grid(True, which='both', ls=\"-\", color='0.65')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1G5fZuNi7f6G"
   },
   "outputs": [],
   "source": [
    "DETCurve(far, frr)\n",
    "# plt.savefig(\"result.png\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "06f4daed54834229bd39ed00588c8cd3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f3362de27cc4cf086568d7ba6f47a84": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a96f4f57da9f4f7ea9abced04b6135fb",
       "IPY_MODEL_fbf9886cdd8c48f3bb3e194939e1b63f"
      ],
      "layout": "IPY_MODEL_06f4daed54834229bd39ed00588c8cd3"
     }
    },
    "2e46656ca04a421a9cbcf506e67537e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e2e96e9bbe14bba9acb549723d14624": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5038d67d35b448409aea3e2a008b4c3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a96f4f57da9f4f7ea9abced04b6135fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e46656ca04a421a9cbcf506e67537e8",
      "max": 4958839,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5038d67d35b448409aea3e2a008b4c3c",
      "value": 4958839
     }
    },
    "effa53e54ffb45bebb27e0bc1e61e483": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbf9886cdd8c48f3bb3e194939e1b63f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_effa53e54ffb45bebb27e0bc1e61e483",
      "placeholder": "​",
      "style": "IPY_MODEL_4e2e96e9bbe14bba9acb549723d14624",
      "value": " 4.73M/4.73M [04:43&lt;00:00, 17.5kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
